// UDWeave sparse matrix vector product.
// David Gleich (based on the Jose's initial programs)
// and hopefully future contributions from others.
// input:
// - a pointer to sparse matrix data as a long list of packed
//     long, long, double
//   entries. so if there are nnz entries, the data has length 24*nnz bytes
// - a pointer to a right hand side vector x
// - a pointer to an output vector y
// - the length of y
// - the number of nonzeros
// - a blocksize to use in mapping to threads. (currently hardcoded as 0x00200)
// on termination:
// - y will be overwritten by the entries of A*x
//
// Recall:
// y_i = sum_j A_{ij} x_j
// so for each non-zero entry (i,j,Aij), we will
// emit an increment Aij*xj to send to yi.
//
// Method:
// - for each yi we create an accumulator thread that has an "accumulate" event
// - for blocks of non-zeros, we create an emitter thread that reads from DRAM
//   and sends events to the accumulator threads
// Limitations:
// notes: this may slow down a lot for highly skewed distributions...
// notes: meant to be simple to get something working initially :)
// notes: the thread creation seems like the it needs more scalability
//         so we aren't creating everything from one starting thread.
// notes: lots of places to probably improve stuff
// key note: if you see // ?? that means I currently don't know exactly what to do here yet.
// but I think we have some idea that something can go there to make it work.
//
// this is the controller thread, it inits itself and
// 1. creates accumulator threads that will do the local accumulation for each entry of y
// 2. creates the emitter threads that will read from DRAM and send Aij*xj to y
// 3. sends the terminate command to the accumulators which instructs them to
//    write to DRAM and end.

// BLOCKSIZE=0x00200

thread spmv { 
  long number_of_emits;
  long ysize; 
  event init(long* nonzeros, double* x, double* y, int nnz, int _ysize, int blocksize) { 
    // compute the number of emits based on the blocksize
    // and handle the case where we don’t easily divide 
    number_of_emits = nnz/0x00200;
    if (number_of_emits*0x00200 < nnz) { 
      number_of_emits = number_of_emits + 1;
    }
   
   // save the value of ysize 
   ysize = _ysize; 


   // create a new event 
   // - NID this is the current node id, what if I want this to go to a separate node?
   // - emitter::init this is the UDweave routine to start the event
   // - 3 this is the number of arguments it takes 
   long evw_reducer = evw_new(NID, accumulator::init, 1);
   // update the event to indicate it should create a new thread
   evw_reducer = evw_update_thread(evw_reducer, NEWTH);

   // TODO - use a tree creation strategy.
   // TODO - how to make this handle more than just one node? 
   for (int i=0; i < ysize; i=i+1) {
     // copied almost verbatim from the broadcast example
     // I’m not sure this dest is correct. 
     // Create a destination ID
     int dest = (NID & 0xFFFF_0000) + i % 64; // currently only one UD
     send_event(evw_reducer, dest, y+i, CCONT); // do I need CCONT here? 
   }
   long evw_emit = evw_new(NID, emitter::init, 2);
   evw_emit = evw_update_thread(evw_emit, NEWTH);
   for (i=0; i < nnz; i=i+0x00200 ) {
     // these will self-terminate.
     dest = (NID & 0xFFFF_0000) + i % 64; // currently only one UD
     send_event(evw_emit, dest, x, nonzeros+i*3*0x00200, CCONT);
   }
 }
 event finish_emit() {
   number_of_emits = number_of_emits-1;
   if (number_of_emits == 0) {
     long evw_reducer = evw_new(NID, accumulator::terminate, 1);
     // update the event to indicate it should create a new thread
     for (int i=0; i < ysize; i=i+1) {
       // send the terminate command to accumulators
       int dest = (NID & 0xFFFF_0000) + i % 64; // currently only one UD
       send_event(evw_reducer, dest, 1, CCONT);
     }
     long* local term;
     term = LMBase; 
     *term = 1; 
     yield_terminate;
   } else {
     yield;
   }
 }
}
// this is the accumulator thread
// notes: in general, you'd want this for a basket of entries.
// and you may want more than one accumulator for each
// this keeps one local variable a.
thread accumulator {
  double a;
  double* final;
  event init(double* result) {
   a = 0.0 ;
   final = result;
  }
  event receive(double val) {
   a = a + val;
  }
  event terminate(int _) {
   send_dram_write(final, a, 8, CCONT); 
   yield_terminate;
  }
}
// emitter threads read a block of entries from the
// sparse matrix and emit products aij*xj
// to the accumulators
thread emitter {
  double* x;
  long rowi;
  double valij; 
  long* nextblock;
  int blocksleft; 
  long nextiterevent;

  event init(double* _x, long* blockstart) {
    x = _x; 
    nextblock = blockstart;
    blocksleft = 0x00200;
    nextiterevent = evw_new(TID, startemit, 1);
    send_event(nextiterevent, TID, 1, CCONT);
  } 


  event startemit(long _) { 
    if (blocksleft == 0) { 
      yield_terminate; 
    } else { 
      long* curblock = nextblock;
      nextblock = curblock + 24;
      blocksleft = blocksleft - 1;
      send_dram_read(curblock, 24, got_nonzero_info);
    }
  } 


  event got_nonzero_info(long* local localdata_from_dram) {
    // extract
    rowi = localdata_from_dram[0];
    long colj = localdata_from_dram[1];
    long valij_long = localdata_from_dram[2];
    // valij = (double) valij_int; // typecast, tbd… 
    valij = 1.0;
    // now read from dram to get the right value of x, and send along the
    // local data.
    // ?? okay, I guess this works slightly differently than I thought. 
    // I was hoping we could forward local data to the destination as well, sort 
    // of like the send_event. But that doesn’t seem to be the case. 
    send_dram_read(x + colj, sizeof(double), got_vector_info);
  }
  event got_vector_info(double* local pxj) {
    double xj = *pxj;
    double val = xj*valij;
    // build the destination ID for yi 
    int dest = (NID & 0xFFFF_0000) + rowi % 64;
    long evw_emit = evw_new(dest, accumulator::receive, 1);
    send_event(evw_emit, dest, val, CCONT); 
    send_event(nextiterevent, TID, 1, CCONT);
  }
}
